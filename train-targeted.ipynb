{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import model.trainer\n",
    "import torch\n",
    "import data.VCTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 entries\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(data.VCTK)\n",
    "dataset = data.VCTK.VCTKDataset(\n",
    "    text_file_paths=[\"resources/tomscott/txt/tomscott.txt\"],\n",
    "    audio_file_paths=[\"resources/tomscott/wav48/tomscott.wav\"]\n",
    ")\n",
    "print(f\"Loaded {len(dataset)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default model\n",
      "Using default vocoder\n",
      "Loading models from checkpoint 300478\n",
      "Models loaded\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model.trainer)\n",
    "trainer = model.trainer.Trainer(\n",
    "    device=torch.device(\"cuda\"),\n",
    "    checkpoint=300478,\n",
    "    checkpoint_dir=\"checkpoints/tom\",\n",
    "    load_from_checkpoint=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training 10 epochs, logging every 1, saving every 10, batch size 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/dom/Project/data/VCTK.py:76: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168786/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  return text, torch.tensor(clips), torch.tensor(spectros)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 batch=0/1 total_loss=2.99297 spectro_loss=1.96168 vocoder_loss=1.03128\n",
      "epoch=0 batch=1/2 total_loss=7.16833 spectro_loss=2.54194 vocoder_loss=4.62639\n",
      "epoch=0 batch=2/3 total_loss=6.88999 spectro_loss=1.84365 vocoder_loss=5.04634\n",
      "epoch=0 batch=3/4 total_loss=4.68984 spectro_loss=1.97989 vocoder_loss=2.70995\n",
      "epoch=0 batch=4/5 total_loss=3.81380 spectro_loss=1.73049 vocoder_loss=2.08331\n",
      "epoch=0 batch=5/6 total_loss=5.52765 spectro_loss=2.11316 vocoder_loss=3.41449\n",
      "epoch=0 batch=6/7 total_loss=5.44205 spectro_loss=1.71681 vocoder_loss=3.72524\n",
      "epoch=0 batch=7/8 total_loss=3.61754 spectro_loss=1.29513 vocoder_loss=2.32241\n",
      "epoch=0 batch=8/9 total_loss=3.22720 spectro_loss=1.72968 vocoder_loss=1.49752\n",
      "epoch=0 batch=9/10 total_loss=2.89721 spectro_loss=1.31237 vocoder_loss=1.58484\n",
      "Saving checkpoint 300488\n",
      "Saved\n",
      "epoch=0 batch=10/11 total_loss=4.02768 spectro_loss=1.69222 vocoder_loss=2.33546\n",
      "epoch=0 batch=11/12 total_loss=3.58910 spectro_loss=1.61379 vocoder_loss=1.97530\n",
      "epoch=0 batch=12/13 total_loss=2.79710 spectro_loss=1.63710 vocoder_loss=1.16000\n",
      "epoch=0 batch=13/14 total_loss=3.15871 spectro_loss=2.02709 vocoder_loss=1.13163\n",
      "epoch=0 batch=14/15 total_loss=2.89772 spectro_loss=1.52153 vocoder_loss=1.37619\n",
      "epoch=0 batch=15/16 total_loss=2.75751 spectro_loss=1.31312 vocoder_loss=1.44439\n",
      "epoch=0 batch=16/17 total_loss=2.76785 spectro_loss=1.45407 vocoder_loss=1.31379\n",
      "epoch=0 batch=17/18 total_loss=2.45313 spectro_loss=1.50898 vocoder_loss=0.94414\n",
      "epoch=0 batch=18/19 total_loss=2.20446 spectro_loss=1.42724 vocoder_loss=0.77723\n",
      "epoch=0 batch=19/20 total_loss=2.55051 spectro_loss=1.60001 vocoder_loss=0.95050\n",
      "Saving checkpoint 300498\n",
      "Saved\n",
      "epoch=0 batch=20/21 total_loss=1.79022 spectro_loss=0.96794 vocoder_loss=0.82228\n",
      "epoch=0 batch=21/22 total_loss=2.85259 spectro_loss=1.88768 vocoder_loss=0.96490\n",
      "epoch=0 batch=22/23 total_loss=2.25868 spectro_loss=1.46458 vocoder_loss=0.79410\n",
      "epoch=0 batch=23/24 total_loss=2.43136 spectro_loss=1.52741 vocoder_loss=0.90395\n",
      "epoch=0 batch=24/25 total_loss=3.23737 spectro_loss=2.15966 vocoder_loss=1.07771\n",
      "epoch=0 batch=25/26 total_loss=2.59098 spectro_loss=1.77172 vocoder_loss=0.81926\n",
      "epoch=0 batch=26/27 total_loss=2.16601 spectro_loss=1.34244 vocoder_loss=0.82357\n",
      "epoch=0 batch=27/28 total_loss=2.56886 spectro_loss=1.90688 vocoder_loss=0.66198\n",
      "epoch=0 batch=28/29 total_loss=1.83809 spectro_loss=1.15117 vocoder_loss=0.68691\n",
      "epoch=0 batch=29/30 total_loss=2.06582 spectro_loss=1.44830 vocoder_loss=0.61753\n",
      "Saving checkpoint 300508\n",
      "Saved\n",
      "epoch=0 batch=30/31 total_loss=2.78865 spectro_loss=1.79816 vocoder_loss=0.99049\n",
      "epoch=0 batch=31/32 total_loss=1.54130 spectro_loss=1.01111 vocoder_loss=0.53019\n",
      "epoch=0 batch=32/33 total_loss=1.98604 spectro_loss=1.36335 vocoder_loss=0.62269\n",
      "epoch=0 batch=33/34 total_loss=2.61661 spectro_loss=1.79031 vocoder_loss=0.82630\n",
      "epoch=0 batch=34/35 total_loss=1.69712 spectro_loss=1.15389 vocoder_loss=0.54323\n",
      "epoch=0 batch=35/36 total_loss=1.67594 spectro_loss=1.20631 vocoder_loss=0.46963\n",
      "epoch=0 batch=36/37 total_loss=1.27803 spectro_loss=0.77305 vocoder_loss=0.50498\n",
      "epoch=0 batch=37/38 total_loss=2.15507 spectro_loss=1.64363 vocoder_loss=0.51144\n",
      "epoch=0 batch=38/39 total_loss=1.29536 spectro_loss=0.96868 vocoder_loss=0.32669\n",
      "epoch=0 batch=39/40 total_loss=0.77694 spectro_loss=0.53216 vocoder_loss=0.24478\n",
      "Saving checkpoint 300518\n",
      "Saved\n",
      "epoch=0 batch=40/41 total_loss=3.30000 spectro_loss=2.62251 vocoder_loss=0.67749\n",
      "epoch=0 batch=41/42 total_loss=0.95875 spectro_loss=0.84028 vocoder_loss=0.11847\n",
      "epoch=1 batch=0/42 total_loss=2.44074 spectro_loss=1.97082 vocoder_loss=0.46992\n",
      "epoch=1 batch=1/42 total_loss=3.07509 spectro_loss=2.25996 vocoder_loss=0.81513\n",
      "epoch=1 batch=2/42 total_loss=2.10549 spectro_loss=1.65144 vocoder_loss=0.45406\n",
      "epoch=1 batch=3/42 total_loss=2.46679 spectro_loss=1.91700 vocoder_loss=0.54979\n",
      "epoch=1 batch=4/42 total_loss=1.96729 spectro_loss=1.62168 vocoder_loss=0.34561\n",
      "epoch=1 batch=5/42 total_loss=2.66752 spectro_loss=1.98686 vocoder_loss=0.68066\n",
      "epoch=1 batch=6/42 total_loss=2.12252 spectro_loss=1.60655 vocoder_loss=0.51596\n",
      "epoch=1 batch=7/42 total_loss=1.70833 spectro_loss=1.19203 vocoder_loss=0.51630\n",
      "epoch=1 batch=8/42 total_loss=2.01213 spectro_loss=1.64851 vocoder_loss=0.36362\n",
      "epoch=1 batch=9/42 total_loss=1.82465 spectro_loss=1.21575 vocoder_loss=0.60890\n",
      "Saving checkpoint 300530\n",
      "Saved\n",
      "epoch=1 batch=10/42 total_loss=1.99615 spectro_loss=1.58164 vocoder_loss=0.41451\n",
      "epoch=1 batch=11/42 total_loss=1.90742 spectro_loss=1.51342 vocoder_loss=0.39400\n",
      "epoch=1 batch=12/42 total_loss=2.00708 spectro_loss=1.55536 vocoder_loss=0.45171\n",
      "epoch=1 batch=13/42 total_loss=2.34453 spectro_loss=1.96336 vocoder_loss=0.38118\n",
      "epoch=1 batch=14/42 total_loss=2.02799 spectro_loss=1.45198 vocoder_loss=0.57602\n",
      "epoch=1 batch=15/42 total_loss=1.86586 spectro_loss=1.24680 vocoder_loss=0.61906\n",
      "epoch=1 batch=16/42 total_loss=1.81534 spectro_loss=1.40108 vocoder_loss=0.41427\n",
      "epoch=1 batch=17/42 total_loss=2.06651 spectro_loss=1.44232 vocoder_loss=0.62419\n",
      "epoch=1 batch=18/42 total_loss=1.68073 spectro_loss=1.36011 vocoder_loss=0.32062\n",
      "epoch=1 batch=19/42 total_loss=2.08033 spectro_loss=1.55101 vocoder_loss=0.52932\n",
      "Saving checkpoint 300540\n",
      "Saved\n",
      "epoch=1 batch=20/42 total_loss=1.33542 spectro_loss=0.92671 vocoder_loss=0.40871\n",
      "epoch=1 batch=21/42 total_loss=2.14335 spectro_loss=1.85921 vocoder_loss=0.28414\n",
      "epoch=1 batch=22/42 total_loss=2.03763 spectro_loss=1.42484 vocoder_loss=0.61279\n",
      "epoch=1 batch=23/42 total_loss=1.86515 spectro_loss=1.49297 vocoder_loss=0.37217\n",
      "epoch=1 batch=24/42 total_loss=2.80167 spectro_loss=2.13320 vocoder_loss=0.66847\n",
      "epoch=1 batch=25/42 total_loss=2.20700 spectro_loss=1.74530 vocoder_loss=0.46170\n",
      "epoch=1 batch=26/42 total_loss=1.83366 spectro_loss=1.31887 vocoder_loss=0.51479\n",
      "epoch=1 batch=27/42 total_loss=2.57873 spectro_loss=1.89006 vocoder_loss=0.68866\n",
      "epoch=1 batch=28/42 total_loss=1.63356 spectro_loss=1.12825 vocoder_loss=0.50531\n",
      "epoch=1 batch=29/42 total_loss=1.84704 spectro_loss=1.43361 vocoder_loss=0.41343\n",
      "Saving checkpoint 300550\n",
      "Saved\n",
      "epoch=1 batch=30/42 total_loss=2.25496 spectro_loss=1.78281 vocoder_loss=0.47214\n",
      "epoch=1 batch=31/42 total_loss=1.46266 spectro_loss=0.97497 vocoder_loss=0.48769\n",
      "epoch=1 batch=32/42 total_loss=1.85075 spectro_loss=1.34422 vocoder_loss=0.50654\n",
      "epoch=1 batch=33/42 total_loss=2.47690 spectro_loss=1.77548 vocoder_loss=0.70142\n",
      "epoch=1 batch=34/42 total_loss=1.55212 spectro_loss=1.13350 vocoder_loss=0.41863\n",
      "epoch=1 batch=35/42 total_loss=1.54399 spectro_loss=1.19467 vocoder_loss=0.34932\n",
      "epoch=1 batch=36/42 total_loss=1.08330 spectro_loss=0.76297 vocoder_loss=0.32032\n",
      "epoch=1 batch=37/42 total_loss=1.95434 spectro_loss=1.62487 vocoder_loss=0.32947\n",
      "epoch=1 batch=38/42 total_loss=1.30564 spectro_loss=0.96140 vocoder_loss=0.34424\n",
      "epoch=1 batch=39/42 total_loss=0.83000 spectro_loss=0.51614 vocoder_loss=0.31387\n",
      "Saving checkpoint 300560\n",
      "Saved\n",
      "epoch=1 batch=40/42 total_loss=3.24999 spectro_loss=2.61173 vocoder_loss=0.63826\n",
      "epoch=1 batch=41/42 total_loss=0.96499 spectro_loss=0.83122 vocoder_loss=0.13377\n",
      "epoch=2 batch=0/42 total_loss=2.38908 spectro_loss=1.95636 vocoder_loss=0.43272\n",
      "epoch=2 batch=1/42 total_loss=2.75601 spectro_loss=2.25136 vocoder_loss=0.50465\n",
      "epoch=2 batch=2/42 total_loss=2.27939 spectro_loss=1.64599 vocoder_loss=0.63340\n",
      "epoch=2 batch=3/42 total_loss=2.42804 spectro_loss=1.90644 vocoder_loss=0.52160\n",
      "epoch=2 batch=4/42 total_loss=2.04657 spectro_loss=1.61690 vocoder_loss=0.42967\n",
      "epoch=2 batch=5/42 total_loss=2.63231 spectro_loss=1.97503 vocoder_loss=0.65728\n",
      "epoch=2 batch=6/42 total_loss=2.05807 spectro_loss=1.59774 vocoder_loss=0.46034\n",
      "epoch=2 batch=7/42 total_loss=1.60124 spectro_loss=1.18478 vocoder_loss=0.41646\n",
      "epoch=2 batch=8/42 total_loss=2.38019 spectro_loss=1.64491 vocoder_loss=0.73528\n",
      "epoch=2 batch=9/42 total_loss=1.68300 spectro_loss=1.21318 vocoder_loss=0.46981\n",
      "Saving checkpoint 300572\n",
      "Saved\n",
      "epoch=2 batch=10/42 total_loss=2.06986 spectro_loss=1.57626 vocoder_loss=0.49360\n",
      "epoch=2 batch=11/42 total_loss=2.13702 spectro_loss=1.50340 vocoder_loss=0.63362\n",
      "epoch=2 batch=12/42 total_loss=1.98304 spectro_loss=1.54980 vocoder_loss=0.43325\n",
      "epoch=2 batch=13/42 total_loss=2.24802 spectro_loss=1.95894 vocoder_loss=0.28908\n",
      "epoch=2 batch=14/42 total_loss=2.10101 spectro_loss=1.45873 vocoder_loss=0.64227\n",
      "epoch=2 batch=15/42 total_loss=1.67343 spectro_loss=1.24678 vocoder_loss=0.42665\n",
      "epoch=2 batch=16/42 total_loss=1.88513 spectro_loss=1.39647 vocoder_loss=0.48866\n",
      "epoch=2 batch=17/42 total_loss=1.63983 spectro_loss=1.44029 vocoder_loss=0.19955\n",
      "epoch=2 batch=18/42 total_loss=1.66608 spectro_loss=1.35921 vocoder_loss=0.30688\n",
      "epoch=2 batch=19/42 total_loss=2.08087 spectro_loss=1.55263 vocoder_loss=0.52824\n",
      "Saving checkpoint 300582\n",
      "Saved\n",
      "epoch=2 batch=20/42 total_loss=1.24332 spectro_loss=0.92201 vocoder_loss=0.32130\n",
      "epoch=2 batch=21/42 total_loss=2.33989 spectro_loss=1.85603 vocoder_loss=0.48386\n",
      "epoch=2 batch=22/42 total_loss=1.69860 spectro_loss=1.42168 vocoder_loss=0.27692\n",
      "epoch=2 batch=23/42 total_loss=1.98058 spectro_loss=1.48978 vocoder_loss=0.49080\n",
      "epoch=2 batch=24/42 total_loss=2.61821 spectro_loss=2.13065 vocoder_loss=0.48755\n",
      "epoch=2 batch=25/42 total_loss=2.09445 spectro_loss=1.74041 vocoder_loss=0.35403\n",
      "epoch=2 batch=26/42 total_loss=1.68113 spectro_loss=1.31594 vocoder_loss=0.36519\n",
      "epoch=2 batch=27/42 total_loss=2.22255 spectro_loss=1.89101 vocoder_loss=0.33154\n",
      "epoch=2 batch=28/42 total_loss=1.44466 spectro_loss=1.12645 vocoder_loss=0.31821\n",
      "epoch=2 batch=29/42 total_loss=1.73285 spectro_loss=1.42727 vocoder_loss=0.30558\n",
      "Saving checkpoint 300592\n",
      "Saved\n",
      "epoch=2 batch=30/42 total_loss=2.09673 spectro_loss=1.78221 vocoder_loss=0.31452\n",
      "epoch=2 batch=31/42 total_loss=1.24194 spectro_loss=0.97073 vocoder_loss=0.27122\n",
      "epoch=2 batch=32/42 total_loss=1.56557 spectro_loss=1.34270 vocoder_loss=0.22288\n",
      "epoch=2 batch=33/42 total_loss=2.22237 spectro_loss=1.77262 vocoder_loss=0.44974\n",
      "epoch=2 batch=34/42 total_loss=1.62790 spectro_loss=1.13393 vocoder_loss=0.49396\n",
      "epoch=2 batch=35/42 total_loss=1.43788 spectro_loss=1.19457 vocoder_loss=0.24331\n",
      "epoch=2 batch=36/42 total_loss=1.28586 spectro_loss=0.76155 vocoder_loss=0.52431\n",
      "epoch=2 batch=37/42 total_loss=2.33358 spectro_loss=1.62081 vocoder_loss=0.71277\n",
      "epoch=2 batch=38/42 total_loss=1.24871 spectro_loss=0.95762 vocoder_loss=0.29109\n",
      "epoch=2 batch=39/42 total_loss=0.69778 spectro_loss=0.51334 vocoder_loss=0.18444\n",
      "Saving checkpoint 300602\n",
      "Saved\n",
      "epoch=2 batch=40/42 total_loss=3.24214 spectro_loss=2.61067 vocoder_loss=0.63147\n",
      "epoch=2 batch=41/42 total_loss=0.95801 spectro_loss=0.83336 vocoder_loss=0.12465\n",
      "epoch=3 batch=0/42 total_loss=2.47805 spectro_loss=1.95647 vocoder_loss=0.52157\n",
      "epoch=3 batch=1/42 total_loss=2.61097 spectro_loss=2.25046 vocoder_loss=0.36051\n",
      "epoch=3 batch=2/42 total_loss=2.00551 spectro_loss=1.64757 vocoder_loss=0.35795\n",
      "epoch=3 batch=3/42 total_loss=2.34756 spectro_loss=1.90484 vocoder_loss=0.44271\n",
      "epoch=3 batch=4/42 total_loss=1.81865 spectro_loss=1.61201 vocoder_loss=0.20664\n",
      "epoch=3 batch=5/42 total_loss=2.23933 spectro_loss=1.97127 vocoder_loss=0.26806\n",
      "epoch=3 batch=6/42 total_loss=1.93265 spectro_loss=1.59687 vocoder_loss=0.33578\n",
      "epoch=3 batch=7/42 total_loss=1.67178 spectro_loss=1.18870 vocoder_loss=0.48308\n",
      "epoch=3 batch=8/42 total_loss=2.08634 spectro_loss=1.64370 vocoder_loss=0.44264\n",
      "epoch=3 batch=9/42 total_loss=1.67256 spectro_loss=1.21013 vocoder_loss=0.46242\n",
      "Saving checkpoint 300614\n",
      "Saved\n",
      "epoch=3 batch=10/42 total_loss=2.05903 spectro_loss=1.57771 vocoder_loss=0.48132\n",
      "epoch=3 batch=11/42 total_loss=1.94842 spectro_loss=1.50487 vocoder_loss=0.44354\n",
      "epoch=3 batch=12/42 total_loss=1.94075 spectro_loss=1.54994 vocoder_loss=0.39081\n",
      "epoch=3 batch=13/42 total_loss=2.60481 spectro_loss=1.95832 vocoder_loss=0.64649\n",
      "epoch=3 batch=14/42 total_loss=1.99257 spectro_loss=1.45954 vocoder_loss=0.53302\n",
      "epoch=3 batch=15/42 total_loss=1.70192 spectro_loss=1.25304 vocoder_loss=0.44887\n",
      "epoch=3 batch=16/42 total_loss=1.90873 spectro_loss=1.40009 vocoder_loss=0.50864\n",
      "epoch=3 batch=17/42 total_loss=1.74311 spectro_loss=1.44129 vocoder_loss=0.30182\n",
      "epoch=3 batch=18/42 total_loss=1.68844 spectro_loss=1.36537 vocoder_loss=0.32308\n",
      "epoch=3 batch=19/42 total_loss=1.93742 spectro_loss=1.55398 vocoder_loss=0.38344\n",
      "Saving checkpoint 300624\n",
      "Saved\n",
      "epoch=3 batch=20/42 total_loss=1.11191 spectro_loss=0.92787 vocoder_loss=0.18404\n",
      "epoch=3 batch=21/42 total_loss=2.29578 spectro_loss=1.85950 vocoder_loss=0.43627\n",
      "epoch=3 batch=22/42 total_loss=1.78574 spectro_loss=1.42262 vocoder_loss=0.36312\n",
      "epoch=3 batch=23/42 total_loss=1.84210 spectro_loss=1.49129 vocoder_loss=0.35081\n",
      "epoch=3 batch=24/42 total_loss=2.63683 spectro_loss=2.13340 vocoder_loss=0.50344\n",
      "epoch=3 batch=25/42 total_loss=2.07513 spectro_loss=1.74130 vocoder_loss=0.33383\n",
      "epoch=3 batch=26/42 total_loss=1.83074 spectro_loss=1.31668 vocoder_loss=0.51406\n",
      "epoch=3 batch=27/42 total_loss=2.45813 spectro_loss=1.89343 vocoder_loss=0.56470\n",
      "epoch=3 batch=28/42 total_loss=1.48356 spectro_loss=1.13379 vocoder_loss=0.34977\n",
      "epoch=3 batch=29/42 total_loss=1.85201 spectro_loss=1.42726 vocoder_loss=0.42475\n",
      "Saving checkpoint 300634\n",
      "Saved\n",
      "epoch=3 batch=30/42 total_loss=2.13861 spectro_loss=1.77866 vocoder_loss=0.35996\n",
      "epoch=3 batch=31/42 total_loss=1.20114 spectro_loss=0.97842 vocoder_loss=0.22273\n",
      "epoch=3 batch=32/42 total_loss=1.65156 spectro_loss=1.34345 vocoder_loss=0.30811\n",
      "epoch=3 batch=33/42 total_loss=1.96485 spectro_loss=1.77016 vocoder_loss=0.19470\n",
      "epoch=3 batch=34/42 total_loss=1.36507 spectro_loss=1.13358 vocoder_loss=0.23149\n",
      "epoch=3 batch=35/42 total_loss=1.44853 spectro_loss=1.19608 vocoder_loss=0.25245\n",
      "epoch=3 batch=36/42 total_loss=0.94341 spectro_loss=0.76699 vocoder_loss=0.17642\n",
      "epoch=3 batch=37/42 total_loss=1.86191 spectro_loss=1.62253 vocoder_loss=0.23938\n",
      "epoch=3 batch=38/42 total_loss=1.23860 spectro_loss=0.95395 vocoder_loss=0.28465\n",
      "epoch=3 batch=39/42 total_loss=0.76674 spectro_loss=0.51604 vocoder_loss=0.25070\n",
      "Saving checkpoint 300644\n",
      "Saved\n",
      "epoch=3 batch=40/42 total_loss=3.10289 spectro_loss=2.61317 vocoder_loss=0.48972\n",
      "epoch=3 batch=41/42 total_loss=0.93748 spectro_loss=0.82895 vocoder_loss=0.10853\n",
      "epoch=4 batch=0/42 total_loss=2.44199 spectro_loss=1.95370 vocoder_loss=0.48830\n",
      "epoch=4 batch=1/42 total_loss=2.82882 spectro_loss=2.25317 vocoder_loss=0.57566\n",
      "epoch=4 batch=2/42 total_loss=2.06710 spectro_loss=1.64767 vocoder_loss=0.41943\n",
      "epoch=4 batch=3/42 total_loss=2.16909 spectro_loss=1.90462 vocoder_loss=0.26448\n",
      "epoch=4 batch=4/42 total_loss=2.07192 spectro_loss=1.61638 vocoder_loss=0.45554\n",
      "epoch=4 batch=5/42 total_loss=2.46758 spectro_loss=1.97316 vocoder_loss=0.49442\n",
      "epoch=4 batch=6/42 total_loss=1.95569 spectro_loss=1.59350 vocoder_loss=0.36218\n",
      "epoch=4 batch=7/42 total_loss=1.46117 spectro_loss=1.18494 vocoder_loss=0.27622\n",
      "epoch=4 batch=8/42 total_loss=2.11408 spectro_loss=1.64250 vocoder_loss=0.47159\n",
      "epoch=4 batch=9/42 total_loss=1.54685 spectro_loss=1.21218 vocoder_loss=0.33467\n",
      "Saving checkpoint 300656\n",
      "Saved\n",
      "epoch=4 batch=10/42 total_loss=1.96070 spectro_loss=1.57355 vocoder_loss=0.38715\n",
      "epoch=4 batch=11/42 total_loss=1.78172 spectro_loss=1.50403 vocoder_loss=0.27770\n",
      "epoch=4 batch=12/42 total_loss=1.92139 spectro_loss=1.55204 vocoder_loss=0.36935\n",
      "epoch=4 batch=13/42 total_loss=2.37022 spectro_loss=1.95699 vocoder_loss=0.41322\n",
      "epoch=4 batch=14/42 total_loss=1.72845 spectro_loss=1.45213 vocoder_loss=0.27632\n",
      "epoch=4 batch=15/42 total_loss=1.45037 spectro_loss=1.24633 vocoder_loss=0.20404\n",
      "epoch=4 batch=16/42 total_loss=1.66242 spectro_loss=1.39823 vocoder_loss=0.26419\n",
      "epoch=4 batch=17/42 total_loss=1.67596 spectro_loss=1.43968 vocoder_loss=0.23628\n",
      "epoch=4 batch=18/42 total_loss=1.58641 spectro_loss=1.36049 vocoder_loss=0.22591\n",
      "epoch=4 batch=19/42 total_loss=1.90935 spectro_loss=1.54917 vocoder_loss=0.36018\n",
      "Saving checkpoint 300666\n",
      "Saved\n",
      "epoch=4 batch=20/42 total_loss=1.17773 spectro_loss=0.92359 vocoder_loss=0.25414\n",
      "epoch=4 batch=21/42 total_loss=2.22259 spectro_loss=1.85285 vocoder_loss=0.36974\n",
      "epoch=4 batch=22/42 total_loss=1.68849 spectro_loss=1.42529 vocoder_loss=0.26320\n",
      "epoch=4 batch=23/42 total_loss=1.80147 spectro_loss=1.49158 vocoder_loss=0.30989\n",
      "epoch=4 batch=24/42 total_loss=2.38367 spectro_loss=2.13175 vocoder_loss=0.25193\n",
      "epoch=4 batch=25/42 total_loss=1.98226 spectro_loss=1.74008 vocoder_loss=0.24218\n",
      "epoch=4 batch=26/42 total_loss=1.51022 spectro_loss=1.31833 vocoder_loss=0.19189\n",
      "epoch=4 batch=27/42 total_loss=2.20553 spectro_loss=1.89480 vocoder_loss=0.31073\n",
      "epoch=4 batch=28/42 total_loss=1.26910 spectro_loss=1.13196 vocoder_loss=0.13714\n",
      "epoch=4 batch=29/42 total_loss=1.65367 spectro_loss=1.42819 vocoder_loss=0.22549\n",
      "Saving checkpoint 300676\n",
      "Saved\n",
      "epoch=4 batch=30/42 total_loss=1.95525 spectro_loss=1.78394 vocoder_loss=0.17131\n",
      "epoch=4 batch=31/42 total_loss=1.11498 spectro_loss=0.97835 vocoder_loss=0.13664\n",
      "epoch=4 batch=32/42 total_loss=1.52215 spectro_loss=1.33957 vocoder_loss=0.18258\n",
      "epoch=4 batch=33/42 total_loss=1.99241 spectro_loss=1.76727 vocoder_loss=0.22514\n",
      "epoch=4 batch=34/42 total_loss=1.39227 spectro_loss=1.13477 vocoder_loss=0.25750\n",
      "epoch=4 batch=35/42 total_loss=1.37160 spectro_loss=1.19404 vocoder_loss=0.17756\n",
      "epoch=4 batch=36/42 total_loss=0.90836 spectro_loss=0.76434 vocoder_loss=0.14402\n",
      "epoch=4 batch=37/42 total_loss=1.85117 spectro_loss=1.62453 vocoder_loss=0.22664\n",
      "epoch=4 batch=38/42 total_loss=1.18392 spectro_loss=0.95711 vocoder_loss=0.22682\n",
      "epoch=4 batch=39/42 total_loss=0.66761 spectro_loss=0.51760 vocoder_loss=0.15001\n",
      "Saving checkpoint 300686\n",
      "Saved\n",
      "epoch=4 batch=40/42 total_loss=2.79501 spectro_loss=2.61272 vocoder_loss=0.18229\n",
      "epoch=4 batch=41/42 total_loss=0.94300 spectro_loss=0.83121 vocoder_loss=0.11179\n",
      "epoch=5 batch=0/42 total_loss=2.49070 spectro_loss=1.95595 vocoder_loss=0.53475\n",
      "epoch=5 batch=1/42 total_loss=2.57136 spectro_loss=2.25306 vocoder_loss=0.31830\n",
      "epoch=5 batch=2/42 total_loss=2.37373 spectro_loss=1.64750 vocoder_loss=0.72623\n",
      "epoch=5 batch=3/42 total_loss=2.70910 spectro_loss=1.90737 vocoder_loss=0.80173\n",
      "epoch=5 batch=4/42 total_loss=2.21771 spectro_loss=1.61501 vocoder_loss=0.60270\n",
      "epoch=5 batch=5/42 total_loss=2.19904 spectro_loss=1.97401 vocoder_loss=0.22503\n",
      "epoch=5 batch=6/42 total_loss=2.26165 spectro_loss=1.59536 vocoder_loss=0.66628\n",
      "epoch=5 batch=7/42 total_loss=1.57333 spectro_loss=1.18874 vocoder_loss=0.38459\n",
      "epoch=5 batch=8/42 total_loss=2.10149 spectro_loss=1.64461 vocoder_loss=0.45689\n",
      "epoch=5 batch=9/42 total_loss=1.54953 spectro_loss=1.21255 vocoder_loss=0.33698\n",
      "Saving checkpoint 300698\n",
      "Saved\n",
      "epoch=5 batch=10/42 total_loss=2.15659 spectro_loss=1.57669 vocoder_loss=0.57990\n",
      "epoch=5 batch=11/42 total_loss=1.80804 spectro_loss=1.50664 vocoder_loss=0.30139\n",
      "epoch=5 batch=12/42 total_loss=2.08060 spectro_loss=1.55536 vocoder_loss=0.52524\n",
      "epoch=5 batch=13/42 total_loss=2.73299 spectro_loss=1.95878 vocoder_loss=0.77421\n",
      "epoch=5 batch=14/42 total_loss=1.77016 spectro_loss=1.45923 vocoder_loss=0.31093\n",
      "epoch=5 batch=15/42 total_loss=1.77487 spectro_loss=1.25093 vocoder_loss=0.52394\n",
      "epoch=5 batch=16/42 total_loss=1.96595 spectro_loss=1.39869 vocoder_loss=0.56726\n",
      "epoch=5 batch=17/42 total_loss=1.83155 spectro_loss=1.44320 vocoder_loss=0.38835\n",
      "epoch=5 batch=18/42 total_loss=1.51914 spectro_loss=1.36186 vocoder_loss=0.15728\n",
      "epoch=5 batch=19/42 total_loss=1.98344 spectro_loss=1.55600 vocoder_loss=0.42744\n",
      "Saving checkpoint 300708\n",
      "Saved\n",
      "epoch=5 batch=20/42 total_loss=1.16664 spectro_loss=0.93007 vocoder_loss=0.23657\n",
      "epoch=5 batch=21/42 total_loss=2.21457 spectro_loss=1.85603 vocoder_loss=0.35853\n",
      "epoch=5 batch=22/42 total_loss=1.72633 spectro_loss=1.42451 vocoder_loss=0.30182\n",
      "epoch=5 batch=23/42 total_loss=1.88720 spectro_loss=1.49063 vocoder_loss=0.39657\n",
      "epoch=5 batch=24/42 total_loss=2.36395 spectro_loss=2.13016 vocoder_loss=0.23378\n",
      "epoch=5 batch=25/42 total_loss=2.11039 spectro_loss=1.74275 vocoder_loss=0.36763\n",
      "epoch=5 batch=26/42 total_loss=1.58750 spectro_loss=1.31804 vocoder_loss=0.26946\n",
      "epoch=5 batch=27/42 total_loss=2.12240 spectro_loss=1.89553 vocoder_loss=0.22688\n",
      "epoch=5 batch=28/42 total_loss=1.38943 spectro_loss=1.13354 vocoder_loss=0.25588\n",
      "epoch=5 batch=29/42 total_loss=1.72665 spectro_loss=1.43291 vocoder_loss=0.29375\n",
      "Saving checkpoint 300718\n",
      "Saved\n",
      "epoch=5 batch=30/42 total_loss=2.11976 spectro_loss=1.78186 vocoder_loss=0.33789\n",
      "epoch=5 batch=31/42 total_loss=1.32659 spectro_loss=0.97760 vocoder_loss=0.34899\n",
      "epoch=5 batch=32/42 total_loss=1.70721 spectro_loss=1.34602 vocoder_loss=0.36118\n",
      "epoch=5 batch=33/42 total_loss=2.04667 spectro_loss=1.77386 vocoder_loss=0.27281\n",
      "epoch=5 batch=34/42 total_loss=1.56946 spectro_loss=1.13596 vocoder_loss=0.43350\n",
      "epoch=5 batch=35/42 total_loss=1.71163 spectro_loss=1.19719 vocoder_loss=0.51444\n",
      "epoch=5 batch=36/42 total_loss=1.04571 spectro_loss=0.77227 vocoder_loss=0.27345\n",
      "epoch=5 batch=37/42 total_loss=1.95133 spectro_loss=1.62728 vocoder_loss=0.32405\n",
      "epoch=5 batch=38/42 total_loss=1.32158 spectro_loss=0.95876 vocoder_loss=0.36282\n",
      "epoch=5 batch=39/42 total_loss=0.84676 spectro_loss=0.51518 vocoder_loss=0.33158\n",
      "Saving checkpoint 300728\n",
      "Saved\n",
      "epoch=5 batch=40/42 total_loss=3.51351 spectro_loss=2.61501 vocoder_loss=0.89850\n",
      "epoch=5 batch=41/42 total_loss=1.06501 spectro_loss=0.83415 vocoder_loss=0.23086\n",
      "epoch=6 batch=0/42 total_loss=2.49242 spectro_loss=1.95603 vocoder_loss=0.53640\n",
      "epoch=6 batch=1/42 total_loss=2.78477 spectro_loss=2.25037 vocoder_loss=0.53440\n",
      "epoch=6 batch=2/42 total_loss=2.00433 spectro_loss=1.64607 vocoder_loss=0.35827\n",
      "epoch=6 batch=3/42 total_loss=2.40088 spectro_loss=1.90688 vocoder_loss=0.49400\n",
      "epoch=6 batch=4/42 total_loss=1.93077 spectro_loss=1.61486 vocoder_loss=0.31591\n",
      "epoch=6 batch=5/42 total_loss=2.49989 spectro_loss=1.97025 vocoder_loss=0.52964\n",
      "epoch=6 batch=6/42 total_loss=1.95133 spectro_loss=1.59519 vocoder_loss=0.35615\n",
      "epoch=6 batch=7/42 total_loss=1.74619 spectro_loss=1.18935 vocoder_loss=0.55684\n",
      "epoch=6 batch=8/42 total_loss=2.29839 spectro_loss=1.64758 vocoder_loss=0.65081\n",
      "epoch=6 batch=9/42 total_loss=1.49870 spectro_loss=1.21932 vocoder_loss=0.27938\n",
      "Saving checkpoint 300740\n",
      "Saved\n",
      "epoch=6 batch=10/42 total_loss=2.27309 spectro_loss=1.57837 vocoder_loss=0.69472\n",
      "epoch=6 batch=11/42 total_loss=2.00991 spectro_loss=1.50375 vocoder_loss=0.50616\n",
      "epoch=6 batch=12/42 total_loss=1.87984 spectro_loss=1.55441 vocoder_loss=0.32543\n",
      "epoch=6 batch=13/42 total_loss=2.54450 spectro_loss=1.95939 vocoder_loss=0.58510\n",
      "epoch=6 batch=14/42 total_loss=1.69528 spectro_loss=1.45568 vocoder_loss=0.23961\n",
      "epoch=6 batch=15/42 total_loss=1.61197 spectro_loss=1.24972 vocoder_loss=0.36226\n",
      "epoch=6 batch=16/42 total_loss=1.71797 spectro_loss=1.39432 vocoder_loss=0.32365\n",
      "epoch=6 batch=17/42 total_loss=1.70835 spectro_loss=1.44108 vocoder_loss=0.26727\n",
      "epoch=6 batch=18/42 total_loss=1.56966 spectro_loss=1.35734 vocoder_loss=0.21232\n",
      "epoch=6 batch=19/42 total_loss=1.80548 spectro_loss=1.55142 vocoder_loss=0.25406\n",
      "Saving checkpoint 300750\n",
      "Saved\n",
      "epoch=6 batch=20/42 total_loss=1.15205 spectro_loss=0.92631 vocoder_loss=0.22573\n",
      "epoch=6 batch=21/42 total_loss=2.15028 spectro_loss=1.85566 vocoder_loss=0.29462\n",
      "epoch=6 batch=22/42 total_loss=1.72159 spectro_loss=1.42348 vocoder_loss=0.29811\n",
      "epoch=6 batch=23/42 total_loss=1.67036 spectro_loss=1.48707 vocoder_loss=0.18329\n",
      "epoch=6 batch=24/42 total_loss=2.54499 spectro_loss=2.13090 vocoder_loss=0.41409\n",
      "epoch=6 batch=25/42 total_loss=1.99343 spectro_loss=1.74199 vocoder_loss=0.25143\n",
      "epoch=6 batch=26/42 total_loss=1.69602 spectro_loss=1.31794 vocoder_loss=0.37808\n",
      "epoch=6 batch=27/42 total_loss=2.29773 spectro_loss=1.88950 vocoder_loss=0.40823\n",
      "epoch=6 batch=28/42 total_loss=1.44320 spectro_loss=1.13076 vocoder_loss=0.31244\n",
      "epoch=6 batch=29/42 total_loss=1.85575 spectro_loss=1.43082 vocoder_loss=0.42493\n",
      "Saving checkpoint 300760\n",
      "Saved\n",
      "epoch=6 batch=30/42 total_loss=2.10874 spectro_loss=1.78238 vocoder_loss=0.32636\n",
      "epoch=6 batch=31/42 total_loss=1.32238 spectro_loss=0.97915 vocoder_loss=0.34323\n",
      "epoch=6 batch=32/42 total_loss=1.70007 spectro_loss=1.34603 vocoder_loss=0.35404\n",
      "epoch=6 batch=33/42 total_loss=2.35354 spectro_loss=1.77656 vocoder_loss=0.57697\n",
      "epoch=6 batch=34/42 total_loss=1.45750 spectro_loss=1.13801 vocoder_loss=0.31949\n",
      "epoch=6 batch=35/42 total_loss=1.63877 spectro_loss=1.19638 vocoder_loss=0.44239\n",
      "epoch=6 batch=36/42 total_loss=1.09241 spectro_loss=0.76697 vocoder_loss=0.32544\n",
      "epoch=6 batch=37/42 total_loss=2.00242 spectro_loss=1.63159 vocoder_loss=0.37082\n",
      "epoch=6 batch=38/42 total_loss=1.26395 spectro_loss=0.96082 vocoder_loss=0.30313\n",
      "epoch=6 batch=39/42 total_loss=0.67645 spectro_loss=0.51573 vocoder_loss=0.16072\n",
      "Saving checkpoint 300770\n",
      "Saved\n",
      "epoch=6 batch=40/42 total_loss=3.17646 spectro_loss=2.61437 vocoder_loss=0.56209\n",
      "epoch=6 batch=41/42 total_loss=0.98240 spectro_loss=0.83969 vocoder_loss=0.14271\n",
      "epoch=7 batch=0/42 total_loss=2.53814 spectro_loss=1.96009 vocoder_loss=0.57805\n",
      "epoch=7 batch=1/42 total_loss=2.89249 spectro_loss=2.25198 vocoder_loss=0.64051\n",
      "epoch=7 batch=2/42 total_loss=1.97821 spectro_loss=1.65150 vocoder_loss=0.32671\n",
      "epoch=7 batch=3/42 total_loss=2.41817 spectro_loss=1.91069 vocoder_loss=0.50748\n",
      "epoch=7 batch=4/42 total_loss=1.99215 spectro_loss=1.61401 vocoder_loss=0.37814\n",
      "epoch=7 batch=5/42 total_loss=2.37944 spectro_loss=1.97109 vocoder_loss=0.40835\n",
      "epoch=7 batch=6/42 total_loss=2.19376 spectro_loss=1.59565 vocoder_loss=0.59812\n",
      "epoch=7 batch=7/42 total_loss=1.54071 spectro_loss=1.18768 vocoder_loss=0.35302\n",
      "epoch=7 batch=8/42 total_loss=1.90993 spectro_loss=1.64556 vocoder_loss=0.26437\n",
      "epoch=7 batch=9/42 total_loss=1.45924 spectro_loss=1.21610 vocoder_loss=0.24315\n",
      "Saving checkpoint 300782\n",
      "Saved\n",
      "epoch=7 batch=10/42 total_loss=2.01956 spectro_loss=1.57706 vocoder_loss=0.44250\n",
      "epoch=7 batch=11/42 total_loss=1.92331 spectro_loss=1.50591 vocoder_loss=0.41740\n",
      "epoch=7 batch=12/42 total_loss=1.84347 spectro_loss=1.55296 vocoder_loss=0.29051\n",
      "epoch=7 batch=13/42 total_loss=2.33264 spectro_loss=1.95990 vocoder_loss=0.37274\n",
      "epoch=7 batch=14/42 total_loss=1.77730 spectro_loss=1.45562 vocoder_loss=0.32168\n",
      "epoch=7 batch=15/42 total_loss=1.56005 spectro_loss=1.24604 vocoder_loss=0.31401\n",
      "epoch=7 batch=16/42 total_loss=1.69433 spectro_loss=1.39557 vocoder_loss=0.29876\n",
      "epoch=7 batch=17/42 total_loss=1.69580 spectro_loss=1.43972 vocoder_loss=0.25607\n",
      "epoch=7 batch=18/42 total_loss=1.53789 spectro_loss=1.35813 vocoder_loss=0.17976\n",
      "epoch=7 batch=19/42 total_loss=1.83443 spectro_loss=1.54864 vocoder_loss=0.28579\n",
      "Saving checkpoint 300792\n",
      "Saved\n",
      "epoch=7 batch=20/42 total_loss=1.10020 spectro_loss=0.92287 vocoder_loss=0.17733\n",
      "epoch=7 batch=21/42 total_loss=2.06557 spectro_loss=1.85607 vocoder_loss=0.20949\n",
      "epoch=7 batch=22/42 total_loss=1.60691 spectro_loss=1.42159 vocoder_loss=0.18532\n",
      "epoch=7 batch=23/42 total_loss=1.66615 spectro_loss=1.48678 vocoder_loss=0.17937\n",
      "epoch=7 batch=24/42 total_loss=2.32296 spectro_loss=2.13380 vocoder_loss=0.18916\n",
      "epoch=7 batch=25/42 total_loss=2.12474 spectro_loss=1.74549 vocoder_loss=0.37926\n",
      "epoch=7 batch=26/42 total_loss=1.54042 spectro_loss=1.31678 vocoder_loss=0.22364\n",
      "epoch=7 batch=27/42 total_loss=2.16798 spectro_loss=1.89032 vocoder_loss=0.27766\n",
      "epoch=7 batch=28/42 total_loss=1.32736 spectro_loss=1.13067 vocoder_loss=0.19669\n",
      "epoch=7 batch=29/42 total_loss=1.77622 spectro_loss=1.42852 vocoder_loss=0.34771\n",
      "Saving checkpoint 300802\n",
      "Saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2d9ff177f9b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msave_every_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"runs/tom2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/dom/Project/model/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, epochs, save_every_n, log_every_n, batch_size, run_name)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtotal_clips\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspectro_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocoder_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mspectro_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectro_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dom/Project/model/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, entry, eval)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mmels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_spectros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0my_pred_wavs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocoder\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmels\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0my_pred_wavs_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_wavs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dom/Project/ForwardTacotron/models/fatchord_version.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mels)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36_pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 850\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    851\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    epochs=10,\n",
    "    dataset=dataset,\n",
    "    save_every_n=10,\n",
    "    batch_size=4,\n",
    "    run_name=\"runs/tom2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint 300478\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "trainer.checkpoint+=1\n",
    "trainer.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8505bd93e15232b680218bd613f68dd2d0ec76b40a79f48f6cb2b19121cd32c4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('azureml_py36_pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
