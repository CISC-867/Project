{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data.VCTK' from '/home/azureuser/dom/Project/data/VCTK.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import model.trainer\n",
    "import torch\n",
    "import data.VCTK\n",
    "importlib.reload(model.trainer)\n",
    "importlib.reload(data.VCTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default model\n",
      "Using default vocoder\n",
      "Loading models from checkpoint 30000\n",
      "Models loaded\n"
     ]
    }
   ],
   "source": [
    "trainer = model.trainer.Trainer(\n",
    "    device=torch.device(\"cuda\"),\n",
    "    checkpoint=30000,\n",
    "    load_from_checkpoint=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = model.trainer.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 total_loss=10.79928 spectro_loss=1.39298 vocoder_loss=9.40630 wav_max=0.43339 wav_min=-0.32562\n",
      "2 total_loss=6.84275 spectro_loss=1.44886 vocoder_loss=5.39389 wav_max=0.28436 wav_min=-0.28388\n",
      "3 total_loss=11.08834 spectro_loss=1.36445 vocoder_loss=9.72389 wav_max=0.31684 wav_min=-0.37416\n",
      "4 total_loss=18.88815 spectro_loss=1.32458 vocoder_loss=17.56357 wav_max=0.10062 wav_min=-0.53207\n",
      "5 total_loss=8.60340 spectro_loss=1.41401 vocoder_loss=7.18939 wav_max=0.17414 wav_min=-0.43602\n",
      "6 total_loss=6.69117 spectro_loss=1.44674 vocoder_loss=5.24442 wav_max=0.21036 wav_min=-0.15964\n",
      "7 total_loss=9.98747 spectro_loss=1.44637 vocoder_loss=8.54110 wav_max=0.26169 wav_min=-0.20448\n",
      "8 total_loss=4.66428 spectro_loss=1.44029 vocoder_loss=3.22400 wav_max=0.16680 wav_min=-0.17627\n",
      "9 total_loss=4.28400 spectro_loss=1.36050 vocoder_loss=2.92350 wav_max=0.17912 wav_min=-0.08440\n",
      "10 total_loss=4.17743 spectro_loss=1.34334 vocoder_loss=2.83409 wav_max=0.15508 wav_min=-0.31343\n",
      "11 total_loss=6.94396 spectro_loss=1.35444 vocoder_loss=5.58952 wav_max=0.22113 wav_min=-0.22614\n",
      "12 total_loss=3.15071 spectro_loss=1.36789 vocoder_loss=1.78282 wav_max=0.16303 wav_min=-0.40081\n",
      "13 total_loss=6.41979 spectro_loss=1.38234 vocoder_loss=5.03745 wav_max=0.23400 wav_min=-0.14699\n",
      "14 total_loss=5.10209 spectro_loss=1.39889 vocoder_loss=3.70320 wav_max=0.27689 wav_min=-0.08683\n",
      "15 total_loss=5.70830 spectro_loss=1.41442 vocoder_loss=4.29388 wav_max=0.24850 wav_min=-0.12125\n",
      "16 total_loss=5.34219 spectro_loss=1.38483 vocoder_loss=3.95736 wav_max=0.18929 wav_min=-0.18246\n",
      "17 total_loss=3.02315 spectro_loss=1.37618 vocoder_loss=1.64697 wav_max=0.21472 wav_min=-0.11278\n",
      "18 total_loss=2.75274 spectro_loss=1.35379 vocoder_loss=1.39896 wav_max=0.16218 wav_min=-0.01052\n",
      "19 total_loss=3.59183 spectro_loss=1.35430 vocoder_loss=2.23753 wav_max=0.08248 wav_min=-0.13923\n",
      "20 total_loss=3.20677 spectro_loss=1.32401 vocoder_loss=1.88276 wav_max=0.11250 wav_min=-0.12749\n",
      "21 total_loss=2.88729 spectro_loss=1.30496 vocoder_loss=1.58233 wav_max=0.07927 wav_min=-0.10275\n",
      "22 total_loss=3.17618 spectro_loss=1.26424 vocoder_loss=1.91195 wav_max=0.05193 wav_min=-0.09997\n",
      "23 total_loss=2.31380 spectro_loss=1.22899 vocoder_loss=1.08481 wav_max=0.10646 wav_min=-0.12096\n",
      "24 total_loss=2.80223 spectro_loss=1.19708 vocoder_loss=1.60515 wav_max=0.07365 wav_min=-0.07621\n",
      "25 total_loss=2.85316 spectro_loss=1.15375 vocoder_loss=1.69941 wav_max=0.09899 wav_min=-0.12380\n",
      "26 total_loss=2.30318 spectro_loss=1.12023 vocoder_loss=1.18294 wav_max=0.12629 wav_min=-0.03446\n",
      "27 total_loss=2.09115 spectro_loss=1.08994 vocoder_loss=1.00121 wav_max=0.07601 wav_min=-0.04353\n",
      "28 total_loss=2.46425 spectro_loss=1.05454 vocoder_loss=1.40971 wav_max=0.02983 wav_min=-0.08152\n",
      "29 total_loss=2.29792 spectro_loss=1.00429 vocoder_loss=1.29363 wav_max=0.08403 wav_min=-0.06403\n",
      "30 total_loss=1.87645 spectro_loss=0.96011 vocoder_loss=0.91634 wav_max=0.09818 wav_min=-0.06280\n",
      "31 total_loss=1.99103 spectro_loss=0.91519 vocoder_loss=1.07584 wav_max=0.04792 wav_min=-0.10275\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7e33c712bc2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspectro_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocoder_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspectro_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_pred_temp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     print(\n",
      "\u001b[0;32m~/dom/Project/model/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, entry)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36_pytorch/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36_pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while True:\n",
    "    total_loss, spectro_loss, vocoder_loss, (spectro_pred, wav_pred, wav_pred_temp) = trainer.train_step(dataset[0])\n",
    "    i+=1\n",
    "    print(\n",
    "        i,\n",
    "        f\"total_loss={total_loss.item():.5f}\",\n",
    "        f\"spectro_loss={spectro_loss.item():.5f}\",\n",
    "        f\"vocoder_loss={vocoder_loss.item():.5f}\",\n",
    "        f\"wav_max={wav_pred.max().item():.5f}\",\n",
    "        f\"wav_min={wav_pred.min().item():.5f}\",\n",
    "    )\n",
    "    if vocoder_loss < 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint 300001\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "trainer.checkpoint = 300001\n",
    "trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 25600])\n",
      "torch.Size([3, 25600])\n"
     ]
    }
   ],
   "source": [
    "wav_pred = wav_pred.to(\"cpu\")\n",
    "print(wav_pred.shape)\n",
    "wav = dataset[0][1]\n",
    "print(wav.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 25600]) torch.float32\n",
      "torch.Size([3, 25600]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "y = wav\n",
    "print(y.shape, y.dtype)\n",
    "# y_hat = wav_pred_temp.transpose(1, 2).unsqueeze(-1).to(\"cpu\")\n",
    "# y_hat = wav_pred_temp.transpose(1, 2).unsqueeze(-1).to(\"cpu\")\n",
    "y_hat = wav_pred.to(\"cpu\")\n",
    "print(y_hat.shape, y_hat.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6752)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1720, -0.6714,  0.3231, -0.4771,  1.0545],\n",
      "        [ 0.1122, -0.7883,  0.2384,  1.8352,  1.2782],\n",
      "        [ 2.0953,  1.7618,  0.0090, -0.8780, -0.4156]], requires_grad=True) tensor([3, 0, 4]) tensor(2.6120, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0240, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "loss = F.cross_entropy(input, target)\n",
    "print(input, target, loss)\n",
    "\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "loss = F.cross_entropy(input, target)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aaf752ee7e264d07f2aa436f1fcdea415bc1d1a9b82629a37d86a1397f966a41"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('azureml_py36_automl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
