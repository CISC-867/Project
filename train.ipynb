{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model.model' from '/home/azureuser/dom/Project/model/model.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data.VCTK\n",
    "import model.model\n",
    "import model.trainer\n",
    "import torch\n",
    "\n",
    "importlib.reload(data.VCTK) # prevent cache when making changes\n",
    "importlib.reload(model.trainer) # prevent cache when making changes\n",
    "importlib.reload(model.model) # prevent cache when making changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.VCTK.VCTKDataset(\"VCTK-Corpus-smaller/\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "myModel = model.model.SpectrogramModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 129])\n",
      "torch.Size([50, 80, 129])\n"
     ]
    }
   ],
   "source": [
    "x = dataset[0][2]\n",
    "x = x[0].unsqueeze(0)\n",
    "print(x.shape)\n",
    "x = x.repeat(50, 1, 1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129184"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(x) for x in list(myModel.parameters())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11996.954624 555.74528 295.996928 259.748352\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "def reasonable(n):\n",
    "    return n/(1000**2)\n",
    "print(reasonable(t),reasonable(r),reasonable(a),reasonable(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4.128256MB\n",
      "torch.Size([100, 80, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/dom/Project/data/VCTK.py:62: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168786/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  return text, torch.tensor(clips), torch.tensor(spectros)\n"
     ]
    }
   ],
   "source": [
    "before = torch.cuda.memory_allocated(0)\n",
    "x = dataset[0][2][0,:,:].to(device).repeat(100,1,1)\n",
    "after = torch.cuda.memory_allocated(0)\n",
    "print(f\"Took {reasonable(after-before):1f}MB\")\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(model.trainer) # prevent cache when making changes\n",
    "myTrainer = model.trainer.Trainer(myModel, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbed6bc7ed3b453094cfbf65b80b4ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5168, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.5275, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.5516, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.5807, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.5696, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.5472, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.5355, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.5308, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.5179, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.5116, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.5048, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.4945, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.4866, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.4849, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.4686, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.4642, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.4439, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.4265, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.4161, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.4083, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.3991, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.3685, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.3706, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.3358, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.3623, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.3100, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.3152, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.2893, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.2539, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.2588, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.2273, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.2095, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.2296, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.2137, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.1787, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.1730, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.1662, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.1434, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.1224, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.1069, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.0885, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.0984, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.0668, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.0501, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.0475, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.0214, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(1.0031, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9883, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9734, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9666, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9494, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9521, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9265, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9293, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9196, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9231, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9022, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.9195, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.8959, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.8744, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.8689, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.8603, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.8343, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.8431, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.8360, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.8113, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.8061, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7967, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.8022, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7829, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7702, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7780, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7596, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7555, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7294, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7549, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7230, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7403, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7388, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7170, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7178, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.7173, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6991, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6975, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6726, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6658, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6539, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6438, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6604, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6689, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6631, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6702, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6473, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6389, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6509, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6029, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "tensor(0.6401, device='cuda:0', grad_fn=<L1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "for i, _ in tqdm.tqdm(list(enumerate(range(0,100)))):\n",
    "    myTrainer.train_step(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os.path\n",
    "checkpoint_dir = pathlib.Path(\"checkpoints\")\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "model_path = checkpoint_dir / \"model1.pth\"\n",
    "if os.path.exists(model_path):\n",
    "    raise Exception(\"Won't overwrite existing models\")\n",
    "else:\n",
    "    torch.save(myModel.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8505bd93e15232b680218bd613f68dd2d0ec76b40a79f48f6cb2b19121cd32c4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('azureml_py36_pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
